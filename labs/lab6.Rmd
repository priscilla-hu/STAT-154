---
title: "lab6"
author: "Priscilla"
date: "10/14/2019"
output: pdf_document
---

## 6.6 Lab 2: Ridge Regression and the Lasso

```{r}
setwd("/Users/priscilla/Desktop/UC Berkeley/Stat 154/lab_csv")
library(ISLR)
names(Hitters)
```

```{r}
x=model.matrix(Salary~.,Hitters)[,-1] 
y=Hitters$Salary[-which(is.na(Hitters$Salary))]
```

## 6.6.1 Ridge Regression

```{r}
library(glmnet)
grid=10^seq(10,-2,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
```

when lambda = 11,498, along with their l2 norm:

```{r}
ridge.mod$lambda [50]

coef(ridge.mod)[,50]

sqrt(sum(coef(ridge.mod)[-1,50]^2))
```

the coefficients when lambda = 705, along with their l2 norm

```{r}
ridge.mod$lambda [60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
```

obtain the ridge regression coefficients for a new value of lambda, say 50:
 
```{r}
predict(ridge.mod,s=50,type="coefficients")[1:20,]
```

split the samples into a training set and a test set

```{r}
set.seed (1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
```

fit a ridge regression model on the training set, and evaluate its MSE on the test set, using lambda = 4.

```{r}
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh =1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,]) 
mean((ridge.pred-y.test)^2)
```

if we had instead simply fit a model with just an intercept

```{r}
#mean((mean(y[train])-y.test)^2)
```

```{r}
#ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,]) 
#mean((ridge.pred-y.test)^2)
```

check whether there is any benefit to performing ridge regression with lambda = 4 instead of just performing least squares regression. 

```{r}
# OLS
ridge.pred=predict(ridge.mod,s=0,newx=x[test,]) 
mean((ridge.pred-y.test)^2)

lm(y~x, subset=train)
predict(ridge.mod,s=0,type="coefficients")[1:20,]
```

use cross-validation to choose the tuning parameter lambda

```{r}
set.seed (1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
```

Therefore, we see that the value of lambda that results in the smallest cross- validation error is 212. What is the test MSE associated with this value of lambda?

```{r}
ridge.pred=predict(ridge.mod,s=bestlam ,newx=x[test,])
mean((ridge.pred-y.test)^2)
```

Finally, we refit our ridge regression model on the full data set, using the value of lambda chosen by cross-validation, and examine the coefficient estimates.

```{r}
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
```


## 6.6.2 The Lasso

```{r}
lasso.mod=glmnet(x[train ,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
```

perform cross-validation and compute the associated test error

```{r}
set.seed (1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[test,])
mean((lasso.pred-y.test)^2)
```

```{r}
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.coef
lasso.coef[lasso.coef!=0]
```

## 6.7 Lab 3: PCR and PLS Regression


## 6.7.1Principal Components Regression

```{r}
library(pls)
set.seed (2)
pcr.fit=pcr(Salary~., data=Hitters ,scale=TRUE, validation ="CV")
```

The resulting fit can be examined using summary().

```{r}
summary(pcr.fit)
```

plot the cross-validation scores using the validationplot() function.

```{r}
validationplot(pcr.fit,val.type="MSEP")
```

We now perform PCR on the training data and evaluate its test set performance.

```{r}
set.seed (1)
pcr.fit=pcr(Salary~., data=Hitters,subset=train,scale=TRUE, validation ="CV")
validationplot(pcr.fit,val.type="MSEP")
```

We compute the test MSE as follows.

```{r}
pcr.pred=predict(pcr.fit,x[test,],ncomp=7)
mean((pcr.pred-y.test)^2)
```

Finally, we fit PCR on the full data set, using M = 7, the number of components identified by cross-validation.

```{r}
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
summary(pcr.fit)
```


## 6.7.2 Partial Least Squares

```{r}
set.seed(1)
pls.fit=plsr(Salary~., data=Hitters,subset=train,scale=TRUE,validation="CV")
summary(pls.fit)
validationplot(pls.fit,val.type="MSEP")
```

We now evaluate the corresponding test set MSE.

```{r}
pls.pred=predict(pls.fit,x[test,],ncomp=2) 
mean((pls.pred-y.test)^2)
```

Finally, we perform PLS using the full data set, using M = 2, the number of components identified by cross-validation.

```{r}
pls.fit=plsr(Salary~., data=Hitters ,scale=TRUE,ncomp=2)
summary(pls.fit)
```

